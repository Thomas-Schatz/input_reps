{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DTW alignment on the basis of energy\n",
    "\n",
    "(suggested by results from MFCC tests in vowel-discri git)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# generic imports\n",
    "import numpy as np\n",
    "import os.path as path\n",
    "\n",
    "# for feature extraction/storage\n",
    "import soundfile\n",
    "import scipy.fftpack\n",
    "import scipy.signal as sig\n",
    "from librosa.core.spectrum import power_to_db, stft\n",
    "from librosa import filters\n",
    "import h5features\n",
    "\n",
    "# results analysis / plots\n",
    "from scone_phobia import apply_analysis\n",
    "from scone_phobia.analyses.avg_error import avg_error\n",
    "import scone_phobia.metadata.add_metadata as add_metadata\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_wav(wavefile, onset=None, offset=None):\n",
    "    data, fs = soundfile.read(wavefile)\n",
    "    if onset is None:\n",
    "        onset = 0\n",
    "    if offset is None:\n",
    "        offset = len(data)/float(fs)\n",
    "    times = 1/(2*float(fs)) + np.arange(len(data))/float(fs)\n",
    "    data = data[(times>=onset) & (times<=offset)]\n",
    "    return data, fs\n",
    "\n",
    "\n",
    "def extract_mfcc(wav_folder, segments_file, out_file, **kwargs):\n",
    "    segments = {}\n",
    "    with open(segments_file, 'r') as fh:\n",
    "        for line in fh:\n",
    "            seg, wav, onset, offset = line.strip().split()\n",
    "            onset, offset = float(onset), float(offset)\n",
    "            segments[seg] = wav, onset, offset\n",
    "    utts, feats, times = [], [], []\n",
    "    for i, seg in enumerate(segments):\n",
    "        if i % 100 == 0:\n",
    "            print(\"Done {} / {}\".format(i, len(segments)))\n",
    "        wav, onset, offset = segments[seg]\n",
    "        wavefile = path.join(wav_folder, wav)\n",
    "        data, fs = read_wav(wavefile, onset=onset, offset=offset)\n",
    "        assert fs == 16000\n",
    "        coefs = mfcc.mfcc(data, **kwargs)\n",
    "        feats.append(coefs.T)\n",
    "        utts.append(seg)\n",
    "        times.append(0.0125 + np.arange(coefs.shape[1])*0.01)\n",
    "    data = h5features.Data(utts, times, feats, check=True)\n",
    "    with h5features.Writer(out_file) as fh:\n",
    "        fh.write(data, '/features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data, fs = soundfile.read('./bras.wav')\n",
    "assert fs == 16000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test ABX discriminability on WSJ corpus\n",
    "\n",
    "This requires some of the material from the \"Early phonetic learning without phonetic categories\" paper.\n",
    "\n",
    "\n",
    "### First extract features of interest and store them in h5features format to allow testing ABX phone discriminability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conditions = [('energy', True),  ('energy', False),\n",
    "              ('remove', False), ('remove', True),\n",
    "              (None, False), (None, True)]\n",
    "root = '/Users/admin/Documents/PhD/Data/GPJ_match_WSJ_test/'\n",
    "for zeroth, norm in conditions[1:]:\n",
    "    print(zeroth)\n",
    "    print(norm)\n",
    "    data = extract_mfcc(root + 'wavs/',\n",
    "                        root + 'segments.txt',\n",
    "                        root + 'mfcc/mfcc_{}_{}.features'.format(zeroth, norm),\n",
    "                        zeroth_coef=zeroth, cep_mean_norm=norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run WSJ discrimination on features (done on a remote cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading (or computing if it's the first time) avg_error analysis results with full resamples\n",
    "\n",
    "mp_folder = '/Users/admin/Documents/PhD/Data/vowel_discri/mp_scores'\n",
    "\n",
    "analysis = avg_error\n",
    "df_avg = apply_analysis(analysis, mp_folder,\n",
    "                        add_metadata=add_metadata.language_register,\n",
    "                        resampling=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.catplot(data=df_avg, kind='bar', y='error', hue='model type', x='contrast type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: for within-speaker phone discrimination:\n",
    "    - cepstral mean normalization does not have much effect overall (tends to make consonant a bit harder to discriminate and vowel a bit easier) -> do not do it\n",
    "    - log-energy: big effect unscaled zeroth-order MFCC appears best????\n",
    "        - Does this have to do with DTW aligning signal based on energy profile due to scale unbalance???\n",
    "            -> how come there is this unbalance in the first place, isn't this supposed to be a PCA?\n",
    "                -> maybe log-energy synchronization (DTW or otherwise) + cosine distance on aligned signals without the energy would work very well? (or more generally on signal deconvoluted from pitch+prosody contours)\n",
    "   \n",
    "    - Short-term: take normalized DTW with basic MFCC (no log energy or removing of first coefficient) and no cepstral mean normalization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
